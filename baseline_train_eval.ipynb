{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1JTS8qG2EgNzm5PsOlfIxaWLJiI8kvG09",
      "authorship_tag": "ABX9TyOy3btc8fVXw9nQuM486YES",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sonyharianto1991/multicriteria_healthcheck/blob/main/baseline_train_eval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# ðŸš€ AUTOMATED HEALTH CHECK & ROLLBACK SYSTEM (Prototype)\n",
        "# Baseline Model + Multi-Criteria Evaluation\n",
        "# ==========================================\n",
        "\n",
        "!pip install torch torchvision albumentations timm scikit-learn tqdm numpy scipy pandas matplotlib -q\n",
        "\n",
        "import torch, torchvision, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "from torchvision import transforms, datasets, models\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from tqdm import tqdm\n",
        "from scipy.stats import ks_2samp, entropy\n",
        "from PIL import Image, ImageEnhance, ImageFilter\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"âœ… Device:\", device)\n",
        "\n",
        "# ==========================================\n",
        "# 1ï¸âƒ£ DATASET SETUP\n",
        "# ==========================================\n",
        "data_dir = \"/content/drive/MyDrive/TESIS/dataset/\"  # ubah sesuai folder di Google Drive\n",
        "train_dir = f\"{data_dir}/train\" ## 611 files\n",
        "val_dir   = f\"{data_dir}/val\" ## 76 files\n",
        "test_dir  = f\"{data_dir}/test\" ## 76 files\n",
        "\n",
        "# Transformasi\n",
        "train_tfms = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(0.2,0.2,0.2,0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "])\n",
        "val_tfms = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "])\n",
        "\n",
        "train_ds = datasets.ImageFolder(train_dir, transform=train_tfms)\n",
        "val_ds   = datasets.ImageFolder(val_dir, transform=val_tfms)\n",
        "test_ds  = datasets.ImageFolder(test_dir, transform=val_tfms)\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_dl   = DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=2)\n",
        "test_dl  = DataLoader(test_ds, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "print(\"ðŸ“‚ Classes:\", train_ds.classes)\n",
        "\n",
        "# ==========================================\n",
        "# 2ï¸âƒ£ BASELINE TRAINING (MobileNetV3)\n",
        "# ==========================================\n",
        "model = models.mobilenet_v3_small(weights='IMAGENET1K_V1')\n",
        "model.classifier[3] = nn.Linear(model.classifier[3].in_features, len(train_ds.classes))\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "for epoch in range(5):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    for x, y in tqdm(train_dl, desc=f\"Epoch {epoch+1}\"):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(x)\n",
        "        loss = criterion(out, y)\n",
        "        loss.backward(); optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1} Loss: {running_loss/len(train_dl):.4f}\")\n",
        "\n",
        "torch.save(model.state_dict(), \"mobilenet_baseline.pth\")\n",
        "print(\"ðŸ’¾ Model saved as mobilenet_baseline.pth\")\n",
        "\n",
        "# ==========================================\n",
        "# 3ï¸âƒ£ BASELINE EVALUATION\n",
        "# ==========================================\n",
        "model.eval(); y_true, y_pred, y_prob = [], [], []\n",
        "with torch.no_grad():\n",
        "    for x, y in test_dl:\n",
        "        x = x.to(device)\n",
        "        out = torch.softmax(model(x), dim=1)\n",
        "        pred = out.argmax(1).cpu().numpy()\n",
        "        y_true.extend(y.numpy()); y_pred.extend(pred)\n",
        "        y_prob.extend(out.cpu().numpy())\n",
        "\n",
        "acc = accuracy_score(y_true, y_pred)\n",
        "f1  = f1_score(y_true, y_pred, average='macro')\n",
        "print(f\"ðŸ“Š Baseline Accuracy: {acc:.4f}, F1: {f1:.4f}\")\n",
        "\n",
        "confidences = [p.max() for p in y_prob]\n",
        "np.save(\"baseline_conf.npy\", confidences)\n",
        "pd.DataFrame({'y_true':y_true,'y_pred':y_pred,'conf':confidences}).to_csv(\"baseline_eval.csv\",index=False)\n",
        "print(\"ðŸ“ Saved baseline_conf.npy and baseline_eval.csv\")\n",
        "\n",
        "# ==========================================\n",
        "# 4ï¸âƒ£ MULTI-CRITERIA METRICS\n",
        "# ==========================================\n",
        "def population_stability_index(expected, actual, bins=10):\n",
        "    def scale_range(input, min=0, max=1):\n",
        "        input += -(np.min(input))\n",
        "        input /= np.max(input) / (max - min)\n",
        "        input += min\n",
        "        return input\n",
        "    expected, actual = scale_range(np.array(expected)), scale_range(np.array(actual))\n",
        "    breakpoints = np.arange(0, bins+1) / bins\n",
        "    expected_perc, _ = np.histogram(expected, breakpoints)\n",
        "    actual_perc, _  = np.histogram(actual, breakpoints)\n",
        "    expected_perc = expected_perc / len(expected)\n",
        "    actual_perc = actual_perc / len(actual)\n",
        "    psi = np.sum((expected_perc - actual_perc) * np.log((expected_perc + 1e-8) / (actual_perc + 1e-8)))\n",
        "    return psi\n",
        "\n",
        "def kl_divergence(p, q, bins=50):\n",
        "    p_hist, _ = np.histogram(p, bins=bins, density=True)\n",
        "    q_hist, _ = np.histogram(q, bins=bins, density=True)\n",
        "    p_hist += 1e-10; q_hist += 1e-10\n",
        "    p_hist /= np.sum(p_hist); q_hist /= np.sum(q_hist)\n",
        "    return entropy(p_hist, q_hist)\n",
        "\n",
        "def aggregate_multi_metrics(y_true, y_pred, conf_base, conf_now, w=[0.2,0.15,0.15,0.15,0.2,0.15]):\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
        "    rec = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
        "    psi = population_stability_index(conf_base, conf_now)\n",
        "    kld = kl_divergence(conf_base, conf_now)\n",
        "    acc_r = 1 - acc; prec_r = 1 - prec; rec_r = 1 - rec; f1_r = 1 - f1\n",
        "    psi_r = min(psi/0.25,1); kld_r = min(kld/1.0,1)\n",
        "    score = np.dot(w, [acc_r,prec_r,rec_r,f1_r,psi_r,kld_r])\n",
        "    return {\"acc\":acc,\"prec\":prec,\"rec\":rec,\"f1\":f1,\"psi\":psi,\"kld\":kld,\"score\":score}\n",
        "\n",
        "# ==========================================\n",
        "# 5ï¸âƒ£ DRIFT SIMULATION & HEALTH CHECK\n",
        "# ==========================================\n",
        "# Reuse baseline model\n",
        "model = models.mobilenet_v3_small()\n",
        "model.classifier[3] = torch.nn.Linear(model.classifier[3].in_features, 2)\n",
        "model.load_state_dict(torch.load(\"mobilenet_baseline.pth\", map_location=device))\n",
        "model = model.to(device).eval()\n",
        "\n",
        "test_tfms = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "])\n",
        "test_ds = datasets.ImageFolder(test_dir, transform=test_tfms)\n",
        "test_dl = DataLoader(test_ds, batch_size=32, shuffle=False)\n",
        "\n",
        "# Simulate drift: brightness + blur\n",
        "def apply_drift(img):\n",
        "    img = img.convert(\"RGB\")\n",
        "    img = ImageEnhance.Brightness(img).enhance(0.6)\n",
        "    img = img.filter(ImageFilter.GaussianBlur(radius=2))\n",
        "    return img\n",
        "\n",
        "# Apply drift simulation (optional)\n",
        "# You can rebuild dataset with drifted images if needed\n",
        "\n",
        "base_conf = np.load(\"baseline_conf.npy\")\n",
        "\n",
        "y_true, y_pred, conf_now = [], [], []\n",
        "with torch.no_grad():\n",
        "    for (x,y) in tqdm(test_dl, desc=\"Evaluating Drifted Model\"):\n",
        "        x = x.to(device)\n",
        "        probs = torch.softmax(model(x), dim=1)\n",
        "        y_pred.extend(probs.argmax(1).cpu().numpy())\n",
        "        y_true.extend(y.numpy())\n",
        "        conf_now.extend(probs.max(1)[0].cpu().numpy())\n",
        "\n",
        "results = aggregate_multi_metrics(y_true, y_pred, base_conf, conf_now)\n",
        "print(\"\\nðŸ“ˆ Multi-Criteria Evaluation Results:\")\n",
        "print(pd.Series(results))\n",
        "\n",
        "status = \"âš ï¸ DEGRADE\" if results['score'] >= 0.7 else \"âœ… OK\"\n",
        "print(f\"\\nFinal Model Health Status: {status} | Score = {results['score']:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-o64lXx60zu7",
        "outputId": "10db4874-99cc-458b-ee18-468dc37474e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Device: cpu\n",
            "ðŸ“‚ Classes: ['1', '2']\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_small-047dcff4.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.83M/9.83M [00:00<00:00, 61.9MB/s]\n",
            "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:53<00:00,  3.15s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Loss: 0.6166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:35<00:00,  2.10s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Loss: 0.5263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:36<00:00,  2.12s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Loss: 0.4740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:34<00:00,  2.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Loss: 0.4080\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:35<00:00,  2.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 Loss: 0.3560\n",
            "ðŸ’¾ Model saved as mobilenet_baseline.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Baseline Accuracy: 0.7895, F1: 0.6833\n",
            "ðŸ“ Saved baseline_conf.npy and baseline_eval.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Drifted Model: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“ˆ Multi-Criteria Evaluation Results:\n",
            "acc      0.789474\n",
            "prec     0.832504\n",
            "rec      0.664479\n",
            "f1       0.683333\n",
            "psi      0.000000\n",
            "kld      0.000000\n",
            "score    0.165058\n",
            "dtype: float64\n",
            "\n",
            "Final Model Health Status: âœ… OK | Score = 0.165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}